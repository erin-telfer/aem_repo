{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference model constraint"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Testing how to create reference model for each sounding\n",
    "Erin Telfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how many n soundings\n",
    "# create matix with n columns\n",
    "# use standard/input parameters\n",
    "# allow user to input own parameters at certain location\n",
    "\n",
    "## cell by sounding n or by coordinates??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## User requirement: enter the folder location where the .dat file is saved\n",
    "folder= str(r\"C:/Users/u67397/AnacondaProjects/aem/input_data/\")\n",
    "\n",
    "## User requirement: enter the name of the second .dat file (without the \".dat\" text)\n",
    "dat_name= str(\"AA140005_Line1080\")\n",
    "\n",
    "## User requirement: enter the reference model conductivity specified for result file\n",
    "reference_EC1= 0.001\n",
    "\n",
    "## User requirement: enter the number of layers result file\n",
    "layers= 30\n",
    "\n",
    "## User requirement: enter the name of the second .dat file (without the \".dat\" text)\n",
    "con_name= str(\"galeisbstdem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## User requirement: enter the folder location where to save files into\n",
    "\n",
    "output_folder= str(r\"C:/Users/u67397/AnacondaProjects/aem/output_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enter additional information. Create tests. e.g. 3 layers at xxx location with xxx EC values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat= pd.read_fwf(folder+dat_name+\".dat\", header=None)\n",
    "datlen= len(dat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#thickness from con file\n",
    "con = pd.read_csv (folder+con_name+\".con\", header=None) #import control file\n",
    "con.replace(regex=True,to_replace=r'\\t', value=r'', inplace=True)#remove tabs\n",
    "tlayers=con.loc[con[0].str.contains('Thickness      = ')] #create a dataframe that contains layer thickness saved in confile (.con)\n",
    "thicknessoflayers= tlayers.replace(regex=True,to_replace=r'Thickness      = ', value=r'')\n",
    "thicknessoflayers=thicknessoflayers[0].str.split((' '),expand=True).replace('',np.nan)\n",
    "thicknessoflayers.dropna(axis=1,inplace=True)\n",
    "thicknessoflayers=thicknessoflayers.reset_index(drop=True).T.reset_index(drop=True).T\n",
    "thicknessoflayers=thicknessoflayers.transpose().astype(float)\n",
    "bottomlayer=thicknessoflayers[0].iloc[-1]\n",
    "bottomlayer=np.array([bottomlayer])\n",
    "bottomlayer=pd.DataFrame(bottomlayer)\n",
    "thicknessoflayers=thicknessoflayers.append(bottomlayer).reset_index(drop=True)\n",
    "thicknessoflayers=np.cumsum(thicknessoflayers)\n",
    "thicknessoflayers=thicknessoflayers.transpose()\n",
    "thicknessoflayers=(pd.np.tile(thicknessoflayers, (datlen, 1)))\n",
    "thicknessoflayers=pd.DataFrame(thicknessoflayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EC=pd.Series(reference_EC1)\n",
    "EC=(pd.np.tile(EC, (datlen, layers)))\n",
    "EC=pd.DataFrame(EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#join datafile and layer thickness dataframes\n",
    "alldata=pd.concat([dat,thicknessoflayers,EC], axis=1, join='outer',ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Weighting - adjust to hit reference model. set out to side and botom x layers. \n",
    "## input constraint to relax in horiz space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alldata=alldata.set_index([2,3], drop=False)\n",
    "alldata['all_sumcoord']=alldata[2]+alldata[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#open constraint csv\n",
    "constraint_name=str(\"input_test\") \n",
    "constraint_data= pd.read_csv(folder+constraint_name+\".csv\") #import control file\n",
    "constraint_data['const_sumcoord']=constraint_data['x']+constraint_data['y']\n",
    "constraint_data=constraint_data.set_index(['ID'], drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberoflocations=list(range(layers))\n",
    "numberoflocations=np.asarray(numberoflocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20845, 30)\n",
      "(20845,)\n"
     ]
    }
   ],
   "source": [
    "#create subset of three dataframes and reformat\n",
    "\n",
    "#thickness\n",
    "thickness_1=thicknessoflayers\n",
    "thickness_2= thicknessoflayers[0:1]\n",
    "thickness_2=np.array(thickness_2).squeeze()\n",
    "\n",
    "#coordinates\n",
    "coords_1=pd.DataFrame(dat.iloc[:,2:3])\n",
    "coords_2=coords_1.transpose()\n",
    "coords_2=np.array(coords_2).squeeze()\n",
    "coords_3=pd.DataFrame(dat.iloc[:,3:4])\n",
    "coords_4=coords_3.transpose()\n",
    "coords_4=np.array(coords_4).squeeze()\n",
    "coords_5=pd.np.tile(coords_4, ((len(numberoflocations), 1))).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matched=pd.DataFrame([0,0,0]).transpose().set_index([0])\n",
    "\n",
    "for x in range(len(constraint_data)):\n",
    "    g=(constraint_data.ID[x])\n",
    "    h=(constraint_data.const_sumcoord[x])\n",
    "    alldata[str(g)]= np.abs(alldata.all_sumcoord-h) \n",
    "    matched1=np.argmin(alldata[str(g)])\n",
    "    e_matched=matched1[0]\n",
    "    n_matched=matched1[1]\n",
    "    matched2=pd.DataFrame([g,float(e_matched),float(n_matched)]).transpose().set_index([0]).astype(float)\n",
    "    matched=pd.concat([matched,matched2], axis=0)\n",
    "\n",
    "matched=matched.rename(columns={1:'E_matched',2:'N_matched'}).drop([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_data2= pd.concat([constraint_data, matched],axis=1)\n",
    "constraint_data2=constraint_data2.set_index(['E_matched','N_matched'],drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:            (depth: 30, layers: 30)\n",
       "Coordinates:\n",
       "    easting            float64 2.21e+05\n",
       "  * depth              (depth) float64 3.0 6.3 9.92 13.92 18.32 23.16 28.48 ...\n",
       "  * layers             (layers) int32 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ...\n",
       "Data variables:\n",
       "    ec_dataset         (depth) float64 0.05 0.05 0.05 0.001 0.001 0.001 ...\n",
       "    thickness_dataset  (layers) float64 3.0 6.3 9.92 13.92 18.32 23.16 28.48 ...\n",
       "    northing_dataset   (depth) float64 6.867e+06 6.867e+06 6.867e+06 ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for y in range(len(constraint_data2)):\n",
    "    EC_value1=constraint_data2['v'][y]\n",
    "    zt=constraint_data2['zt'][y]\n",
    "    zb=constraint_data2['zb'][y]\n",
    "    easting=float(\"{0:.2f}\".format(constraint_data2['E_matched'][y]))\n",
    "    northing=float(\"{0:.2f}\".format(constraint_data2['N_matched'][y]))    \n",
    "    #Convert datasets into arrays \n",
    "    \n",
    "    coords1={'easting': coords_2, 'depth':thickness_2} #Create EC array\n",
    "    ec_da = xr.DataArray(EC, dims=('easting', 'depth'), coords=coords1)\n",
    "    \n",
    "    coords2={'easting': coords_2, 'layers': numberoflocations}#Create thickness array\n",
    "    thickness_da = xr.DataArray(thickness_1, dims=('easting', 'layers'), coords=coords2)\n",
    "    \n",
    "    coords3={'easting': coords_2, 'depth': thickness_2}\n",
    "    coords_da = xr.DataArray(coords_5, dims=('easting','depth'), coords=coords3)\n",
    "    \n",
    "    dataset = xr.Dataset({'ec_dataset': ec_da, 'thickness_dataset': thickness_da, 'northing_dataset':coords_da}) #Create combined EC and thickness array\n",
    "    #Change EC values at certain depths\n",
    "    \n",
    "    array2=dataset.assign(ec=EC_value1).where((thickness_da>zt)&(thickness_da<zb)).sel(easting=easting)\n",
    "\n",
    "    array2['ec']=array2.ec.fillna(reference_EC1)\n",
    "    array3=np.array(array2['ec'])\n",
    "    #Create array with updated EC values at certain depths\n",
    "    ec_da.loc[easting]=array3\n",
    "    dataset = xr.Dataset({'ec_dataset': ec_da, 'thickness_dataset': thickness_da, 'northing_dataset':coords_da}) #Create combined EC and thickness array\n",
    "\n",
    "dataset.sel(easting=220955.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EC_value1=constraint_data2['v'][0]\n",
    "zt=constraint_data2['zt'][0]\n",
    "zb=constraint_data2['zb'][0]\n",
    "easting=float(\"{0:.2f}\".format(constraint_data2['E_matched'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coords_5=pd.np.tile(coords_4, ((len(coords_4), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:            (depth: 5, easting: 5, layer: 5, northing: 5)\n",
       "Coordinates:\n",
       "  * easting            (easting) float64 2.21e+05 2.21e+05 2.21e+05 2.21e+05 ...\n",
       "  * depth              (depth) float64 3.0 6.3 9.92 13.92 18.32\n",
       "  * layer              (layer) int32 1 2 3 4 5\n",
       "  * northing           (northing) float64 6.867e+06 6.867e+06 6.867e+06 ...\n",
       "Data variables:\n",
       "    ec_dataset         (easting, depth) float64 0.05 0.05 0.05 0.001 0.001 ...\n",
       "    thickness_dataset  (easting, layer) float64 3.0 6.3 9.92 13.92 18.32 3.0 ...\n",
       "    northing_dataset   (northing, depth) float64 6.867e+06 6.867e+06 ..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert datasets into arrays\n",
    "\n",
    "#Create EC array\n",
    "coords1={'easting':coords_2, 'depth':thickness_2}\n",
    "ec_da = xr.DataArray(EC, dims=('easting', 'depth'), coords=coords1,)\n",
    "\n",
    "#Create thickness array\n",
    "coords2={'easting': coords_2, 'layer': [1, 2, 3, 4, 5]}\n",
    "thickness_da = xr.DataArray(thicknessoflayers, dims=('easting', 'layer'), coords=coords2)\n",
    "\n",
    "#Create thickness array\n",
    "coords3={'northing': coords_4, 'depth': thickness_2}\n",
    "coords_da = xr.DataArray(coords_5, dims=('northing','depth'), coords=coords3)\n",
    "# coords3={'northing': coords_4, 'depth': thickness_2}\n",
    "# coords_da = xr.DataArray(thickness_1, dims=('northing','depth'), coords=coords3)\n",
    "\n",
    "\n",
    "#Create combined EC and thickness array\n",
    "dataset = xr.Dataset({'ec_dataset': ec_da, 'thickness_dataset': thickness_da, 'northing_dataset':coords_da})\n",
    "# dataset = xr.Dataset({'ec': ec_da, 'thickness_name': thickness_da, 'thickness_name2':coords_da})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.001,  0.001,  0.001,  0.1  ,  0.1  ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change EC values at certain depths\n",
    "array2=dataset.assign(ec=EC_value1).where((thickness_da>zt)&(thickness_da<zb)).sel(northing=northing).sel(easting=easting)\n",
    "array2['ec']=array2.ec.fillna(reference_EC1)\n",
    "array3=np.array(array2['ec'])\n",
    "array3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:            (depth: 5, easting: 5, layer: 5, northing: 5)\n",
       "Coordinates:\n",
       "  * easting            (easting) float64 2.21e+05 2.21e+05 2.21e+05 2.21e+05 ...\n",
       "  * depth              (depth) float64 3.0 6.3 9.92 13.92 18.32\n",
       "  * layer              (layer) int32 1 2 3 4 5\n",
       "  * northing           (northing) float64 6.867e+06 6.867e+06 6.867e+06 ...\n",
       "Data variables:\n",
       "    ec_dataset         (easting, depth) float64 0.05 0.05 0.05 0.001 0.001 ...\n",
       "    thickness_dataset  (easting, layer) float64 3.0 6.3 9.92 13.92 18.32 3.0 ...\n",
       "    northing_dataset   (northing, depth) float64 6.867e+06 6.867e+06 ..."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create array with updated EC values at certain depths\n",
    "ec_da.loc[easting]=array3\n",
    "dataset = xr.Dataset({'ec_dataset': ec_da, 'thickness_dataset': thickness_da, 'northing_dataset':coords_da}) #Create combined EC and thickness array\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coords_m=dat.iloc[:,1:3]\n",
    "# EC_1= xr.Dataset(EC.iloc[0:9,0:9])\n",
    "# thickness_m=xr.Dataset(thicknessoflayers.iloc[0:9,0:9])\n",
    "# dat_m=xr.Dataset(dat.iloc[0:9,0:9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset = xarray.Dataset({'ec': ec_da, 'thickness_name': thickness_da})\n",
    "# dataset.ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coords={'location': coords_test, 'layer': [1, 2, 3, 4, 5]}\n",
    "# thickness_da = xarray.DataArray(thickness_m, dims=('location', 'layer'), coords=coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# thickness_test= thickness_m[0:1]\n",
    "# thickness_test=np.array(thickness_test).squeeze()\n",
    "# thickness_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coords_test= coords_m.transpose()\n",
    "# coords_test=np.array(coords_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset.sel(location=220926.1).update({dataset.ec:('ec2',[0.05,  0.05,  0.01,  0.01,  0.01])}, inplace=True)\n",
    "# dataset.sel(location=220926.1).update({'ec':('ec2',[0.05,  0.05,  0.01,  0.01,  0.01])}, inplace=True)\n",
    "#dataset.location[0]#=dataset.sel(location=220926.1)#.update({dataset.ec:('ec2',[0.05,  0.05,  0.01,  0.01,  0.01])}, inplace=True)\n",
    "# dataset.loc['location',['220926.1']]\n",
    "\n",
    "#dataset.update({'ec':('ec',[1,2,3])})\n",
    "#dataset.update({(dataset.sel(location=220926.1).ec):(1)})\n",
    "# dataset.ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create and save a .csv that contains depth of investigation data for input into Discover PA software\n",
    "alldata.to_csv(output_folder+'/depth_data.csv') #save doi data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test2= dataset.sel(location=220926.1)\n",
    "# test2=test2.thickness_name<10#.ec\n",
    "# test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset.ec.isel_points(location=(dataset.thickness_name < 10).location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset.where(dataset.sel(location=51).thickness_name < 10).fillna(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset.location[:] = [5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#coords_m=pd.DataFrame(dat.iloc[0:5,2:4])\n",
    "\n",
    "# test=pd.concat([coords_m,thickness_m,EC_m],axis=1,ignore_index=True).set_index([0,1])\n",
    "# test=pd.concat([test,constraint_data2],axis=1)\n",
    "# test \n",
    "\n",
    "\n",
    "# thickness_m=pd.concat([coords_m,thickness_m],axis=1,ignore_index=True)#.set_index([0,1])\n",
    "# array=np.array([[coords_m],[thickness_m],[EC_m]])\n",
    "# array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for row in constraint_data:\n",
    "#     print(row)\n",
    "    #sample[str(row)]= 0\n",
    "\n",
    "#print(sample)\n",
    "    \n",
    "    \n",
    "#     print('loop1_start')\n",
    "#     print(row)\n",
    "#     print('loop1_ends')\n",
    "#     for blah in constraint_data['const_sumcoord']:\n",
    "#         print('loop2_starts')\n",
    "#         print (blah)\n",
    "#         print('loop2_ends')\n",
    "# #         while x>0:\n",
    "#         for rah in sample:\n",
    "#             sample[str(row)]=np.abs(test.all_sumcoord-blah)\n",
    "# #                 x=x-1\n",
    "#             print(sample)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## find coordinate\n",
    "## enter layer thickness (e.g 3)\n",
    "## extrapolate between the points to maximum layers (e.g. 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# array=np.array([[dat],[thicknessoflayers],[EC]],ndmin=3)\n",
    "# array.shape\n",
    "# #test=np.ndarray(array)\n",
    "# array[[0,0,0],[[0,0,0],[0,0,0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #create a dataframe that contains layer thickness saved in confile (.con)\n",
    "# tlayers=con.loc[con[0].str.contains('Thickness      = ')]\n",
    "# thicknessoflayers= tlayers.replace(regex=True,to_replace=r'Thickness      = ', value=r'')\n",
    "# thicknessoflayers=thicknessoflayers[0].str.split((' '),expand=True).replace('',np.nan)\n",
    "# thicknessoflayers.dropna(axis=1,inplace=True)\n",
    "# thicknessoflayers=(pd.np.tile(thicknessoflayers, (datlen, 1)))\n",
    "# #thicknessoflayers=pd.DataFrame(thicknessoflayers)\n",
    "# thicknessoflayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# thicknessoflayers=(pd.np.tile(thicknessoflayers, (datlen, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coord(easting,northing):\n",
    "    easting=int(easting)\n",
    "    northing=int(northing)\n",
    "    print(type(easting))\n",
    "\n",
    "coord('1','2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_text():\n",
    "    print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [[1, 2, 3, 4], [5, 6], [7, 8, 9]]\n",
    "for i in range(len(a)):\n",
    "    for j in range(len(a[i])):\n",
    "        print(a[i][j], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EC_x=xr.Dataset([EC_m],[thickness_m])\n",
    "# EC_x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
