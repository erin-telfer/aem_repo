{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AEM Reference model constraint"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This notebook can be used to reformat input data in order to constrain AEM inversions that use the GALEISBSTDEM algorithm (Brodie, 2016)\n",
    "\n",
    "\n",
    "**Pre-requirements**\n",
    "1) A model file that is saved to your local drive, is in column delineated ascii format with no header line, and should contain no non-numerics.\n",
    "\n",
    "2) A constraint file that is in .csv format and contains columns of \"ID\", \"easting\", \"northing\", \"top_layer\", and \"layer_conductivity\".\n",
    "\n",
    "3) A complete control file.\n",
    "\n",
    "\n",
    "\n",
    "**Authorship**\n",
    "\n",
    "This code was written in September 2017 by Erin Telfer with support from David McInnes and Ross C Brodie. The notebook was completed as a graduate program project at Geoscience Australia. If you find an error or if you have any suggestions, please contact erin.telfer@ga.gov.au. Alternatively, please contact david.mcinnes@ga.gov.au.\n",
    "\n",
    "\n",
    "***NOTE: this notebook is not complete and still requires more work. The constrained conductivity and weighting values are not constrained laterally.***\n",
    "\n",
    "\n",
    "**Definitions** - update\n",
    "\n",
    "AEM - Airborne Electromagnetic\n",
    "\n",
    "RC - Reference conductivity\n",
    "\n",
    "\"##\" indicates cells that require user modification.\n",
    "\n",
    "\"#\" indicates description of code.  No modification is required.\n",
    "\n",
    "**References**\n",
    "Brodie, R., C., 2016. GALEISBSTDEM - deterministic 1D sample by sample inversion of AEM data. GitHub repository, https://github.com/GeoscienceAustralia/ga-aem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### NOTE: this notebook is not complete and still requires more work. The constrained conductivity and weighting values are not constrained laterally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User requirement: enter details of input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##User requirement: enter the following details for input datasets:\n",
    "\n",
    "##Dataset location. Ensure \"/\" are used, not \"\\\"\n",
    "folder= str(r\"C:/Users/u67397/AnacondaProjects/aem/input_data/\")\n",
    "\n",
    "##Name of the datafile. Include the \".extension\"\n",
    "dat_name= str(\"AA140005_Line1080.dat\")\n",
    "\n",
    "##Name of the Control file. Include the \".extension\"\n",
    "con_name= str(\"galeisbstdem.con\")\n",
    "\n",
    "##Name of constraint file. Include the \".extension\"\n",
    "constraint_name=str(\"input_test.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User requirement: enter the column location for certain data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##User requirement: enter the column location within the datafile.\n",
    "##please do **not** use programmer counting, for example the third column should be \"3\"\n",
    "\n",
    "line_column = 1 ##The column location of the \"Line number\"\n",
    "easting_column = 3 ##The column location of \"easting/x/longitude\" values\n",
    "northing_column = 4 ##The column location of \"northing/y/latitude\" values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User requirement: enter reference model data variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##User requirement: enter the following values relating to the reference model\n",
    "\n",
    "##Enter the reference model conductivity \n",
    "reference_conductivity= 0.001\n",
    "\n",
    "##Enter the number of layers\n",
    "reference_layers= 30\n",
    "\n",
    "##Set constraint weighting. 1% =no constraint (e.g. reference model) and 10%= hard constraint at location\n",
    "no_constraint=1 #Value given to represent reference model\n",
    "hard_constraint=10 #Value given to represent constraint data\n",
    "lateral_constraint=3 #The lateral constraint distance (number of soundings each side of the constraint location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User requirement: enter folder location to save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##User requirement: enter the output folder location. Ensure \"/\" are used, not \"\\\"\n",
    "output_folder= str(r\"C:/Users/u67397/AnacondaProjects/aem/output_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No more user requirements... Just run the remaining cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Location variables are defined. Because python locates columns starting at 0, rather than 1, column values are subtracted \n",
    "easting_column2= easting_column - 1 #Set the location of the easting column within input datafile\n",
    "northing_column2= northing_column - 1 #Set the location of the northing column within input datafile\n",
    "line_column2= line_column -1 #Set the location of the line title column within input datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data is imported\n",
    "dat= pd.read_fwf(folder+dat_name, header=None) #Import data file\n",
    "dat2=dat.set_index([easting_column2,northing_column2], drop=False) #Set coordinates as index\n",
    "dat2['all_sumcoord']=dat2[easting_column2]+dat2[northing_column2] #Create a new column that combines coordinates\n",
    "datlen= len(dat2.index) #Create variable of dat length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thickness data from Control file is imported and formatted\n",
    "con = pd.read_csv (folder+con_name, header=None) #Import control file\n",
    "con.replace(regex=True,to_replace=r'\\t', value=r'', inplace=True)#Remove tabs\n",
    "tlayers=con.loc[con[0].str.contains('Thickness      = ')] #Extract thickness values saved in the Control file and save in dataframe\n",
    "thicknessoflayers= tlayers.replace(regex=True,to_replace=r'Thickness      = ', value=r'')#Remove the words\"Thickness = \" from dataframe\n",
    "thicknessoflayers=thicknessoflayers[0].str.split((' '),expand=True).replace('',np.nan) #Split values and replace spaces with \"nan\"\n",
    "thicknessoflayers.dropna(axis=1,inplace=True) #Remove nan values\n",
    "thicknessoflayers=thicknessoflayers.reset_index(drop=True).T.reset_index(drop=True).astype(float) #Reset index\n",
    "\n",
    "#The bottom layer is duplicated\n",
    "bottomlayer=thicknessoflayers[0].iloc[-1] #Save bottom layer as variable\n",
    "bottomlayer=np.array([bottomlayer]) #Set value as array\n",
    "bottomlayer=pd.DataFrame(bottomlayer) #Set value as dataframe\n",
    "thicknessoflayers=thicknessoflayers.append(bottomlayer).reset_index(drop=True) #Append bottom layer to thickness dataframe\n",
    "depthoflayers=np.cumsum(thicknessoflayers).T #Create a cumulative sum of thickness values\n",
    "depthoflayers=(pd.np.tile(depthoflayers, (datlen, 1))) #Create an array of depth values (soundings x layers)\n",
    "depthoflayers=pd.DataFrame(depthoflayers) #Convert to dataframe\n",
    "\n",
    "#The top layer is defined as a variable\n",
    "all_layers= depthoflayers[0:1] #Save top depths as dataframe \n",
    "all_layers=np.array(all_layers).squeeze() #Convert from dataframe to array and squeeze into correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#An array with the number of reference model layers is created\n",
    "numberoflocations=list(range(reference_layers)) #Create a list of the number of reference model layers\n",
    "numberoflocations=np.asarray(numberoflocations) #Turn list into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A dataframe of reference reference conductivity values is created\n",
    "RC=pd.Series(reference_conductivity) #Turn reference conductivity into a series\n",
    "RC=(pd.np.tile(RC, (datlen, reference_layers))) #Create an array of reference conductivity values (soundings x layers)\n",
    "RC=pd.DataFrame(RC) #Convert array into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>easting</th>\n",
       "      <th>northing</th>\n",
       "      <th>layer_top</th>\n",
       "      <th>layer_bottom</th>\n",
       "      <th>layer_conductivity</th>\n",
       "      <th>constraint_coords_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>erin</th>\n",
       "      <td>erin</td>\n",
       "      <td>220955.6</td>\n",
       "      <td>6867443.6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7088399.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rules</th>\n",
       "      <td>rules</td>\n",
       "      <td>220956.6</td>\n",
       "      <td>6867444.6</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7088401.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID   easting   northing  layer_top  layer_bottom  \\\n",
       "ID                                                           \n",
       "erin    erin  220955.6  6867443.6          0            10   \n",
       "rules  rules  220956.6  6867444.6         10            20   \n",
       "\n",
       "       layer_conductivity  constraint_coords_sum  \n",
       "ID                                                \n",
       "erin                 0.05              7088399.2  \n",
       "rules                0.10              7088401.2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Constraint file is loaded and processed\n",
    "constraint_data= pd.read_csv(folder+constraint_name) #Import control file\n",
    "constraint_data['constraint_coords_sum']=constraint_data['easting']+constraint_data['northing'] #Take sum of easting and northing\n",
    "constraint_data=constraint_data.set_index(['ID'], drop=False)#Set ID as index\n",
    "constraint_data #Print dataframe to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creation of a data array made up of constraint weighting values\n",
    "constraint_weighting=np.full((datlen,reference_layers),no_constraint) #Create an array of constraint weighting values (soundings x layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Coordinates are extracted and processed\n",
    "easting_coords=pd.DataFrame(dat2.iloc[:,(easting_column -1):(easting_column)]) #Extract easting values from data file\n",
    "easting_coords=easting_coords.transpose() #Transpose dataframe\n",
    "easting_coords=np.array(easting_coords).squeeze() #Convert from dataframe to array and squeeze into correct format\n",
    "\n",
    "northing_coords=pd.DataFrame(dat2.iloc[:,(northing_column -1):(northing_column)]) #Extract northing values from data file\n",
    "northing_coords=northing_coords.transpose() #Transpose dataframe\n",
    "northing_coords=np.array(northing_coords).squeeze()  #Convert from dataframe to array and squeeze into correct format\n",
    "\n",
    "northing_array=pd.np.tile(northing_coords, ((len(numberoflocations), 1))).transpose() #Create an array of northing values (soundings x layers)\n",
    "\n",
    "coords_index=pd.DataFrame(dat.iloc[:,(easting_column2):(northing_column2 +1)]).set_index(easting_column-1) #Set coordinates for use in index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coordinates within the constraint data are matched with the closest coordinates in the datafile\n",
    "matched=pd.DataFrame([0,0,0]).transpose().set_index([0]) #Create empty dataframe\n",
    "\n",
    "for all in range(len(constraint_data)): #Match coordinates through loop\n",
    "    constraint_ID=(constraint_data.ID[all])\n",
    "    constraint_coords=(constraint_data.constraint_coords_sum[all]) \n",
    "    dat2[str(constraint_ID)]= np.abs(dat2.all_sumcoord-constraint_coords)  \n",
    "    matched1=np.argmin(dat2[str(constraint_ID)]) \n",
    "    e_matched=matched1[0]\n",
    "    n_matched=matched1[1]\n",
    "    matched2=pd.DataFrame([constraint_ID,float(e_matched),float(n_matched)]).transpose().set_index([0]).astype(float)\n",
    "    matched=pd.concat([matched,matched2], axis=0)\n",
    "\n",
    "matched=matched.rename(columns={1:'east_matched',2:'north_matched'}).drop([0]) #Rename coordinate headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>easting</th>\n",
       "      <th>northing</th>\n",
       "      <th>layer_top</th>\n",
       "      <th>layer_bottom</th>\n",
       "      <th>layer_conductivity</th>\n",
       "      <th>constraint_coords_sum</th>\n",
       "      <th>east_matched</th>\n",
       "      <th>north_matched</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>east_matched</th>\n",
       "      <th>north_matched</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220955.6</th>\n",
       "      <th>6867443.6</th>\n",
       "      <td>erin</td>\n",
       "      <td>220955.6</td>\n",
       "      <td>6867443.6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7088399.2</td>\n",
       "      <td>220955.6</td>\n",
       "      <td>6867443.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220958.6</th>\n",
       "      <th>6867443.7</th>\n",
       "      <td>rules</td>\n",
       "      <td>220956.6</td>\n",
       "      <td>6867444.6</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7088401.2</td>\n",
       "      <td>220958.6</td>\n",
       "      <td>6867443.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ID   easting   northing  layer_top  \\\n",
       "east_matched north_matched                                          \n",
       "220955.6     6867443.6       erin  220955.6  6867443.6          0   \n",
       "220958.6     6867443.7      rules  220956.6  6867444.6         10   \n",
       "\n",
       "                            layer_bottom  layer_conductivity  \\\n",
       "east_matched north_matched                                     \n",
       "220955.6     6867443.6                10                0.05   \n",
       "220958.6     6867443.7                20                0.10   \n",
       "\n",
       "                            constraint_coords_sum  east_matched  north_matched  \n",
       "east_matched north_matched                                                      \n",
       "220955.6     6867443.6                  7088399.2      220955.6      6867443.6  \n",
       "220958.6     6867443.7                  7088401.2      220958.6      6867443.7  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matched coordinates are matched to the constraint dataframe\n",
    "constraint_data2= pd.concat([constraint_data, matched],axis=1) #Join matched coordinates and constraint data\n",
    "constraint_data2=constraint_data2.set_index(['east_matched','north_matched'],drop=False) #Set matched coordinates as index\n",
    "constraint_data2 #Print dataframe to screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#A multidimensional array made up of coordinates, reference conductivity, \n",
    "#layer thicknesses, and weighting is crated.\n",
    "#At the location of constraint, the conductivity and weighting values have been replaced\n",
    "\n",
    "for y in range(len(constraint_data2)): #Create loop and define values\n",
    "    EC_value1=constraint_data2['layer_conductivity'][y]\n",
    "    z_top=constraint_data2['layer_top'][y]\n",
    "    z_bottom=constraint_data2['layer_bottom'][y]\n",
    "    east=float(\"{0:.2f}\".format(constraint_data2['east_matched'][y]))\n",
    "    north=float(\"{0:.2f}\".format(constraint_data2['north_matched'][y]))    \n",
    "    \n",
    "    #Convert datasets into arrays \n",
    "    coords_da1={'easting': easting_coords, 'depth':all_layers} #Create EC array\n",
    "    rc_da = xr.DataArray(RC, dims=('easting', 'depth'), coords=coords_da1)\n",
    "    \n",
    "    coords_da2={'easting': easting_coords, 'layers': numberoflocations}#Create thickness array\n",
    "    thickness_da = xr.DataArray(depthoflayers, dims=('easting', 'layers'), coords=coords_da2)\n",
    "    \n",
    "    coords_da3={'easting': easting_coords, 'depth': all_layers}\n",
    "    northing_da = xr.DataArray(northing_array, dims=('easting','depth'), coords=coords_da3)\n",
    "    \n",
    "    coords_da4={'easting': easting_coords, 'depth': all_layers}\n",
    "    weighting_da = xr.DataArray(constraint_weighting, dims=('easting','depth'), coords=coords_da4)\n",
    "    \n",
    "    dataset = xr.Dataset({'rc_dataset': rc_da, 'thickness_dataset': thickness_da, 'northing_dataset':northing_da, 'weighting_dataset':weighting_da}) #Create combined EC and thickness array\n",
    "    \n",
    "    #Change EC and weighting values at constrained locations/depths\n",
    "    array2=dataset.assign(ec=EC_value1).where((thickness_da>z_top)&(thickness_da<z_bottom)).sel(easting=east)\n",
    "    array2['ec']=array2.ec.fillna(reference_conductivity)\n",
    "    array3=np.array(array2['ec'])\n",
    "    array4=dataset.assign(weighting=hard_constraint).where((thickness_da>z_top)&(thickness_da<z_bottom)).sel(easting=east) \n",
    "    print()\n",
    "    array4['weighting']=array4.weighting.fillna(no_constraint)\n",
    "    array5=np.array(array4['weighting'])\n",
    "    \n",
    "    #Create array with updated EC and weighting values at certain depths\n",
    "    rc_da.loc[east]=array3\n",
    "    weighting_da.loc[east]=array5\n",
    "    dataset = xr.Dataset({'rc_dataset': rc_da, 'thickness_dataset': thickness_da, 'northing_dataset':northing_da, 'weighting_dataset':weighting_da}) #Create combined EC and thickness array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenate original datafile with the new reference conductivity array and the new weighting array\n",
    "rc_df=rc_da.to_pandas() #Convert to from array to dataframe\n",
    "weighting_df=weighting_da.to_pandas() #Convert to from array to dataframe\n",
    "rc_weighting=pd.concat([rc_df,weighting_df],axis=1) #Join conductivity and weighting dataframes\n",
    "rc_weighting['northing']=coords_index #Add northing values\n",
    "rc_weighting=rc_weighting.set_index('northing',append=True) #Set index\n",
    "dat_final=pd.concat([dat2,rc_weighting],axis=1) #Join original datafile with updated constrained data\n",
    "dat_final=dat_final.reset_index(drop=True).T.reset_index(drop=True).T #Reset indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The new datafile is saved as .csv and as .dat\n",
    "dat_final.to_csv(output_folder+(dat_name[:-4])+'_final.dat')\n",
    "dat_final.to_csv(output_folder+(dat_name[:-4])+'_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following code relates to laterally constraining conductivity and weighting values. The code below is only a concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   1.   1.   4.   7.  10.   7.   4.   1.   1.   1.]\n",
      " [  1.   1.   1.   4.   7.  10.   7.   4.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]]\n"
     ]
    }
   ],
   "source": [
    "#Concept for laterally constraining values\n",
    "\n",
    "lateral_test_dataset=np.zeros((15,11)) #Create test dataset\n",
    "lateral_test_dataset[:2,5]=hard_constraint  #Add hard constraint\n",
    "\n",
    "#Return evenly spaced numbers at the specified number of soundings (lateral_constraint)\n",
    "lateral_test_max=np.linspace(hard_constraint,no_constraint,num=lateral_constraint,endpoint=False)\n",
    "lateral_test_min=np.linspace(no_constraint,hard_constraint,num=lateral_constraint,endpoint=False)\n",
    "\n",
    "for row in lateral_test_dataset: #Create a loop that finds any values above 0 (e.g. hard constraint values)\n",
    "    if row.any()>0:\n",
    "        ixx = np.where(row==hard_constraint) #set variable where values = hard constraint\n",
    "        ixx= int(ixx[0]) #set variable for location of hard constraint\n",
    "        \n",
    "        ixx_min_down=ixx-lateral_constraint #Set variable for minimum lateral constraint\n",
    "        ixx_min_up=ixx #Set variable for minimum lateral constraint\n",
    "            \n",
    "        ixx_max_down=ixx #Set variable for maximum lateral constraint\n",
    "        ixx_max_up=ixx+lateral_constraint  #Set variable for maximum lateral constraint\n",
    "        \n",
    "        row[ixx_min_down:ixx_min_up]=lateral_test_min #In locations set above, replace with lateral constrained values\n",
    "        row[ixx_max_down:ixx_max_up]=lateral_test_max #In locations set above, replace with lateral constrained values\n",
    "\n",
    "\n",
    "np.place(lateral_test_dataset,lateral_test_dataset==0,1) #Replace 0 with 1\n",
    "\n",
    "print (lateral_test_dataset) #Print result to screen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
